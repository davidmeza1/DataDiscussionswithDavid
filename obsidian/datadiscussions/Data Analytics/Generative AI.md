Here are a few direct competitors of ChatGPT, and today is Monday, so there will be a couple more by the end of the weekend:  
  
[[PEER by Meta AI]]  
  
[[LaMDA by Google AI]]  
  
[[PaLM by Google AI]]


The more I read about those Large Language Models, the more I feel that very little has changed since 2017's "Attention is all you need":Â [https://lnkd.in/gUts7Sjq](https://lnkd.in/gUts7Sjq)! All those models follow the exact same architecture with a couple of changes here and there. The advancements are mostly happening in the scale of the data and the models and the domain specificity of the data. At those scales, the fun is a lot about how to minimize training costs. I wonder, if I were to train a HUGE XGBoost model with my own HUGE dataset, would I be able to name that model DamienBoost and publish a paper about it?


![graphical user interface, diagram](https://media.licdn.com/dms/image/C5622AQG61WhhMxLWcw/feedshare-shrink_800/0/1675096539775?e=1678924800&v=beta&t=eA5fzk7diiuTAAdhKwbrGUVqQoNcG8u7-mvs0GEa0WA)


[[Large Language Models]]

[[Research Apps]]
